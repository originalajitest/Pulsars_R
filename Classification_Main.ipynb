{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a4445c9",
   "metadata": {},
   "source": [
    "# Prediction of Pulsars and Non-pulsars via Classification - Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90315196",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Pulsars are rotating neutron stars that emit radio waves at regular intervals, and their detection is important in fields such as Astrophysics and Radio Astronomy. However, pulsars are challenging to detect due to interference and noise at radio frequencies, thus giving false signals. To improve detection, machine learning techniques have been employed. \n",
    "\n",
    "The question that we want to address is: Is a new observation a pulsar or non-pulsar based on the statistics of the integrated profile as our predictors? \n",
    "\n",
    "The dataset which we are using to answer this question is the HTRU2 dataset, which contains 17,898 observations of pulsars and non-pulsars, obtained from the High Time Resolution Universe Survey. Each observation has 8 features; mean, standard deviation, excess kurtosis and skewness for both the Integrated Profile and DM-SNR curve. Additionally, a binary label called 'class' is used to indicate whether an observation is a pulsar or not where 0 belongs to non-pulsar and 1 being pulsar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f71c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(recipes)\n",
    "library(tidymodels)\n",
    "library(cowplot)\n",
    "library(GGally)\n",
    "library(tidymodels)\n",
    "library(ggplot2)\n",
    "library(themis)\n",
    "# install.packages(\"https://cran.r-project.org/src/contrib/Archive/themis/themis_1.0.0.tar.gz\", dependencies = TRUE, lib = \"/opt/conda/lib/R/library\", repos=NULL, type=\"source\")\n",
    "# This line is incase I need to install a lib locally, to get the lib use .libPaths()\n",
    "# I have not yet changed any information, just kept for later reference and will adapt it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6350f040-0265-43e5-9e31-14a6a8c1a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723da81a",
   "metadata": {},
   "source": [
    "## Preliminary Exploratory Data Analysis\n",
    "\n",
    "Now, we will read the dataset from the web into R, and then clean our data.  Here, we notice that the class column has 0's and 1's. The 1's mean that the observation is a pulsar, and 0 means non-pulsar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7388020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding the column names to the dataset because they originally did not exist\n",
    "columns <- c(\"mean_ip\", \"std_ip\", \"ek_ip\", \"sk_ip\", \"mean_dmsnr\", \"std_dmsnr\", \"ek_dmsnr\", \"sk_dmsnr\", \"class\")\n",
    "\n",
    "# reading the data, and converting class to factor type\n",
    "pulsar_data <- read_csv(\"https://raw.githubusercontent.com/audst/dsci100-s005-group10/main/data/HTRU_2.csv\", col_names = columns) |>\n",
    "                    mutate(class = as.factor(class))\n",
    "\n",
    "print(\"Table 1\")\n",
    "head(pulsar_data, 10)\n",
    "\n",
    "pulsar_split <- pulsar_data |>\n",
    "                    initial_split(prop=3/4, strata=class)\n",
    "pulsar_training <- training(pulsar_split)\n",
    "pulsar_testing <- testing(pulsar_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04e0074-1f6a-435c-9c5d-057340d248fa",
   "metadata": {},
   "source": [
    "First we will have a quick look at the various graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b2229a-d308-418b-a585-e664cd07edda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_grid(mean_ip_vs_std_ip,mean_ip_vs_ek_ip,mean_ip_vs_sk_ip,std_ip_vs_ek_ip,std_ip_vs_sk_ip,ek_ip_vs_sk_ip, ncol = 4)\n",
    "# plot_grid(mean_dmsnr_vs_std_dmsnr,mean_dmsnr_vs_ek_dmsnr,mean_dmsnr_vs_sk_dmsnr,std_dmsnr_vs_ek_dmsnr,std_dmsnr_vs_sk_dmsnr,ek_dmsnr_vs_sk_dmsnr, ncol = 4)\n",
    "\n",
    "ip_pairs_plot <- pulsar_training |>\n",
    "                select(mean_ip, std_ip, ek_ip, sk_ip, class) |>\n",
    "                ggpairs(aes(color=class)) +\n",
    "                ggtitle(\"[Figure 7]\")\n",
    "                labs(color=class) +\n",
    "                theme(text=element_text(size=30))\n",
    "ip_pairs_plot\n",
    "dmsnr_pairs_plot <- pulsar_training |>\n",
    "                select(mean_dmsnr, std_dmsnr, ek_dmsnr, sk_dmsnr, class) |>\n",
    "                ggpairs(aes(color=class)) +\n",
    "                ggtitle(\"[Figure 7]\")\n",
    "                labs(color=class) +\n",
    "                theme(text=element_text(size=30))\n",
    "dmsnr_pairs_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2da9b14-6c54-4bc6-9d4c-99b8766ec973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61e257a8-e139-42bd-bdaa-1ecb7e1d5522",
   "metadata": {},
   "source": [
    "Now we will try with all fields squared and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ec8ca-bf81-486a-b2c8-d28976241878",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_squared <- pulsar_data |>\n",
    "                    mutate(mean_ip_sq = mean_ip * mean_ip,\n",
    "                           std_ip_sq = std_ip * std_ip,\n",
    "                           ek_ip_sq = ek_ip * ek_ip,\n",
    "                           sk_ip_sq = sk_ip * sk_ip,\n",
    "                           mean_dmsnr_sq = mean_dmsnr * mean_dmsnr,\n",
    "                           std_dmsnr_sq = std_dmsnr * std_dmsnr,\n",
    "                           ek_dmsnr_sq = ek_dmsnr * ek_dmsnr,\n",
    "                           sk_dmsnr_sq = sk_dmsnr * sk_dmsnr) |>\n",
    "                    select(mean_ip_sq, std_ip_sq, ek_ip_sq, sk_ip_sq, mean_dmsnr_sq, std_dmsnr_sq, ek_dmsnr_sq, sk_dmsnr_sq, class)\n",
    "\n",
    "pulsar_split_sq <- pulsar_squared |>\n",
    "                    initial_split(prop=3/4, strata=class)\n",
    "pulsar_training_sq <- training(pulsar_split_sq)\n",
    "pulsar_testing_sq <- testing(pulsar_split_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fdfea6-c765-468c-8acf-98be96716399",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_pairs_plot_sq <- pulsar_training_sq |>\n",
    "                select(mean_ip_sq, std_ip_sq, ek_ip_sq, sk_ip_sq, class) |>\n",
    "                ggpairs(aes(color=class)) +\n",
    "                ggtitle(\"[Figure 7]\")\n",
    "                labs(color=class) +\n",
    "                theme(text=element_text(size=30))\n",
    "ip_pairs_plot_sq\n",
    "dmsnr_pairs_plot_sq <- pulsar_training_sq |>\n",
    "                select(mean_dmsnr_sq, std_dmsnr_sq, ek_dmsnr_sq, sk_dmsnr_sq, class) |>\n",
    "                ggpairs(aes(color=class)) +\n",
    "                ggtitle(\"[Figure 7]\")\n",
    "                labs(color=class) +\n",
    "                theme(text=element_text(size=30))\n",
    "dmsnr_pairs_plot_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b92864",
   "metadata": {},
   "source": [
    "Next, we can select the columns that we plan to use as the predictors, namely mean_ip, std_ip, ek_ip, and sk_ip, along with the class column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3bb9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_data_pred <- pulsar_data |>\n",
    "                        select(mean_ip, std_ip, ek_ip, sk_ip, class)\n",
    "\n",
    "print(\"Table 2\")\n",
    "head(pulsar_data_pred, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e5240",
   "metadata": {},
   "source": [
    "We now have to scale all the potential predictor variables so that the prediction is not influenced by the different scales of all the predictors, thus avoiding inaccurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4872b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_scaled <- pulsar_data_pred |>\n",
    "                    mutate(mean_ip_scaled = scale(mean_ip, center=TRUE)) |>\n",
    "                    mutate(std_ip_scaled = scale(std_ip, center=TRUE)) |>\n",
    "                    mutate(ek_ip_scaled = scale(ek_ip, center=TRUE)) |>\n",
    "                    mutate(sk_ip_scaled = scale(sk_ip, center=TRUE)) |>\n",
    "                    select(class:sk_ip_scaled)\n",
    "\n",
    "print(\"Table 3\")\n",
    "head(pulsar_scaled, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5988a",
   "metadata": {},
   "source": [
    "Now we can continue with splitting 75% of our data into training and and 25% testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3cbcda",
   "metadata": {},
   "source": [
    "We can now see if we have any missing data in our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54028f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows_missing_data <- pulsar_training |>\n",
    "                          map_df(~sum(is.na(.)))\n",
    "\n",
    "print(\"Table 4\")\n",
    "n_rows_missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecfb2d",
   "metadata": {},
   "source": [
    "Fortunately, we can see that we do not have empty data to deal with, so we can proceed to find out how many observations exist for each class in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f931515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts <- pulsar_training |>\n",
    "                    group_by(class) |>\n",
    "                    dplyr::summarize(count = n())\n",
    "\n",
    "print(\"Table 5\")\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ae474",
   "metadata": {},
   "source": [
    "Here, we notice that there is an overwhelming majority of observations with class 0, which shows how difficult it is to detect pulsars among the rest of the noise and radio frequencies. \n",
    "Now we find the means of all our predictor variables based on the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aee3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "means <- pulsar_training |>\n",
    "            group_by(class) |>\n",
    "            summarize_at(vars(\"mean_ip_scaled\", \"std_ip_scaled\", \"ek_ip_scaled\", \"sk_ip_scaled\"), mean)\n",
    "\n",
    "print(\"Table 6\")\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c1407",
   "metadata": {},
   "source": [
    "Above, we see that the means of the variables vary extensively for the different classes. This reaffirms our choice of predictor variables as the model will be able to predict the different classes with a greater accuracy and less indistinctness. \n",
    "Now we can create a series of plots to find out the relation of the different variables with the class. Each plot matches one predictor variable with another to demonstrate any visual trends that are otherwise unnoticeable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c04806",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 23, repr.plot.height = 7)\n",
    "\n",
    "mean_ip_vs_std_ip <- pulsar_training |>\n",
    "                        ggplot(aes(x=mean_ip_scaled, y=std_ip_scaled, color=class)) +\n",
    "                        geom_point(alpha = 0.3) +\n",
    "                        labs(x=\"Mean of Integrated Profile Scaled\", \n",
    "                             y=\"Standard Deviation of Integrated Profile Scaled\", \n",
    "                             color=\"Class\", \n",
    "                             title=\"[Figure 1] Distribution of Standard Deviation and Mean of Integrated Profile\") +\n",
    "                        theme(text = element_text(size = 15))\n",
    "\n",
    "mean_ip_vs_ek_ip <- pulsar_training |>\n",
    "                        ggplot(aes(x=mean_ip_scaled, y=ek_ip_scaled, color=class)) +\n",
    "                        geom_point(alpha = 0.3) +\n",
    "                        labs(x=\"Mean of Integrated Profile Scaled\", \n",
    "                             y=\"Excess Kurtosis of Integrated Profile Scaled\", \n",
    "                             color=\"Class\", \n",
    "                             title=\"[Figure 2] Distribution of Excess Kurtosis and Mean of Integrated Profile\") +\n",
    "                        theme(text = element_text(size = 15))\n",
    "\n",
    "mean_ip_vs_sk_ip <- pulsar_training |>\n",
    "                        ggplot(aes(x=mean_ip_scaled, y=sk_ip_scaled, color=class)) +\n",
    "                        geom_point(alpha = 0.3) +\n",
    "                        labs(x=\"Mean of Integrated Profile Scaled\", \n",
    "                             y=\"Skewness of Integrated Profile Scaled\", \n",
    "                             color=\"Class\", \n",
    "                             title=\"[Figure 3] Distribution of Skewness and Mean of Integrated Profile\") +\n",
    "                        theme(text = element_text(size = 15))\n",
    "\n",
    "std_ip_vs_ek_ip <- pulsar_training |>\n",
    "                        ggplot(aes(x=std_ip_scaled, y=ek_ip_scaled, color=class)) +\n",
    "                        geom_point(alpha = 0.3) +\n",
    "                        labs(x=\"Standard Deviation of Integrated Profile Scaled\", \n",
    "                             y=\"Excess Kurtosis of Integrated Profile Scaled\", \n",
    "                             color=\"Class\", \n",
    "                             title=\"[Figure 4] Distribution of Standard Deviation and Excess Kurtosis of Integrated Profile\") +\n",
    "                        theme(text = element_text(size = 15))\n",
    "\n",
    "std_ip_vs_sk_ip <- pulsar_training |>\n",
    "                        ggplot(aes(x=std_ip_scaled, y=sk_ip_scaled, color=class)) +\n",
    "                        geom_point(alpha = 0.3) +\n",
    "                        labs(x=\"Standard Deviation of Integrated Profile Scaled\", \n",
    "                             y=\"Skewness of Integrated Profile Scaled\", \n",
    "                             color=\"Class\", \n",
    "                             title=\"[Figure 5] Distribution of Standard Deviation and Skewness of Integrated Profile\") +\n",
    "                        theme(text = element_text(size = 15))\n",
    "\n",
    "ek_ip_vs_sk_ip <- pulsar_training |>\n",
    "                        ggplot(aes(x=ek_ip_scaled, y=sk_ip_scaled, color=class)) +\n",
    "                        geom_point(alpha = 0.3) +\n",
    "                        labs(x=\"Excess Kurtosis of Integrated Profile Scaled\", \n",
    "                             y=\"Skewness of Integrated Profile Scaled\", \n",
    "                             color=\"Class\", \n",
    "                             title=\"[Figure 6] Distribution of Excess Kurtosis and Skewness of Integrated Profile\") +\n",
    "                        theme(text = element_text(size = 15))\n",
    "\n",
    "plot_grid(mean_ip_vs_std_ip,mean_ip_vs_ek_ip)\n",
    "plot_grid(mean_ip_vs_sk_ip,std_ip_vs_ek_ip)\n",
    "plot_grid(std_ip_vs_sk_ip,ek_ip_vs_sk_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa4d39-11d9-44ff-88e3-d609b8277af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 20, repr.plot.height = 20)\n",
    "\n",
    "pairs_plot <- pulsar_training |>\n",
    "                ggpairs(aes(color=class)) +\n",
    "                ggtitle(\"[Figure 7]\")\n",
    "                labs(color=class) +\n",
    "                theme(text=element_text(size=30))\n",
    " \n",
    "pairs_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d39615-e661-4493-90b9-0eb1cf3b4dc0",
   "metadata": {},
   "source": [
    "### Analyzing the graphs and choosing the final predictor variables\n",
    "\n",
    "In the plots above, we see that the scatters of all the predictors have minuscule overlap between our two classes. Thus, we can go ahead and choose all four of these as our final predictor variables, namely mean_ip, std_ip, ek_ip and sk_ip. Even the box plots in Figure 7 show that the overlap between the two classes for the same variable are very small and that these four predictors should be ideal for training our model with. We want to have very less overlap between the two classes for all variables as to get more distinct and significant predictors. \n",
    "\n",
    "Moreover, we notice in the top right bar graph of Figure 7 between the two classes that the class 1 has very few instances compared to class 2. This rarity of class 1 can make the model more biased towards predicting the class 0 more, thus we will have to fix this issue by upsampling the class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d48c6-db0a-42d6-81d4-3f3d1aa9b235",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "Now, we use $K$-nearest neighbors classification and cross validation of 5 folds in order to train our data. Firstly, we will tune the number of neighbors to find the ideal value for $K$. We will thus test for all values of $K$ from 1 to 100 in steps of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5f605-fd35-4b6c-a1e3-b62da8b37bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_upsampled_recipe <- recipe(class ~ mean_ip_scaled, std_ip_scaled, ek_ip_scaled, sk_ip_scaled, data=pulsar_training) |>\n",
    "                              step_upsample(class, over_ratio=1, skip=FALSE) |>\n",
    "                              prep()\n",
    "\n",
    "pulsar_upsampled <- bake(pulsar_upsampled_recipe, pulsar_training)\n",
    "\n",
    "pulsar_recipe <- recipe(class ~ mean_ip_scaled, std_ip_scaled, ek_ip_scaled, sk_ip_scaled, data=pulsar_upsampled) |>\n",
    "                    step_scale(all_predictors()) |>  \n",
    "                    step_center(all_predictors())\n",
    "\n",
    "knn_tune <- nearest_neighbor(weight_func=\"rectangular\", neighbors=tune()) |>\n",
    "                        set_engine(\"kknn\") |>\n",
    "                        set_mode(\"classification\")\n",
    "\n",
    "pulsar_vfold <- vfold_cv(pulsar_upsampled, v=5, strata=class)\n",
    "\n",
    "gridvals <- tibble(neighbors=seq(from=1, to=100, by=10))\n",
    "\n",
    "pulsar_workflow <- workflow() |>\n",
    "                       add_recipe(pulsar_recipe) |>\n",
    "                       add_model(knn_tune) |>\n",
    "                       tune_grid(resamples=pulsar_vfold, grid=gridvals) |>\n",
    "                       collect_metrics()\n",
    "\n",
    "knn_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71bb9a-bba3-4bd2-b67d-f9ed919f767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_in_upsampled <- pulsar_upsampled |>\n",
    "                            group_by(class) |>\n",
    "                            summarize(count = n())\n",
    "\n",
    "print(\"Table 7\")\n",
    "classes_in_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991db255-970c-4adb-9ef3-3f94de0a508c",
   "metadata": {},
   "source": [
    "Above we see in the tibble that the classes are now balanced, and we have tested for various values of $K$. Next, we collect the accuracy metrics and then plot them against the $K$ values in order to find the most suitable value for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf90e0-03a0-451c-9b6d-be5a9df303eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 10)\n",
    "\n",
    "accuracies <- pulsar_workflow |>\n",
    "                  filter(.metric == \"accuracy\") |>\n",
    "                  select(neighbors, mean)\n",
    "\n",
    "accuracy_plot <- ggplot(accuracies, aes(x=neighbors, y=mean)) +\n",
    "                     geom_line() +\n",
    "                     geom_point() +\n",
    "                     labs(x = \"Neighbors\", y = \"Accuracy\", \n",
    "                          title = \"[Figure 8] Accuracies of different values of K\") +\n",
    "                     theme(text = element_text(size = 20))\n",
    "\n",
    "accuracy_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3f435-fb1c-41f9-9582-3d490609a6cf",
   "metadata": {},
   "source": [
    "Above, we see that the accuracy is the highest for the values of $K$ between 0 and 20. Thus, we can test for values for $K$ between 0 and 20 using smaller intervals to get a better and more precise value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8f57b-666e-42c6-bd06-4107a2bcdd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 10)\n",
    "\n",
    "gridvals2 <- tibble(neighbors=seq(from=1, to=20, by=1))\n",
    "\n",
    "pulsar_workflow_2 <- workflow() |>\n",
    "                       add_recipe(pulsar_recipe) |>\n",
    "                       add_model(knn_tune) |>\n",
    "                       tune_grid(resamples=pulsar_vfold, grid=gridvals2) |>\n",
    "                       collect_metrics()\n",
    "\n",
    "accuracies2 <- pulsar_workflow_2 |>\n",
    "                  filter(.metric == \"accuracy\") |>\n",
    "                  select(neighbors, mean)\n",
    "\n",
    "accuracy_plot_2 <- ggplot(accuracies2, aes(x=neighbors, y=mean)) +\n",
    "                     geom_line() +\n",
    "                     geom_point() +\n",
    "                     labs(x = \"Neighbors\", y = \"Accuracy\", \n",
    "                          title = \"[Figure 9] Accuracies of different values of K between 0 and 20\") +\n",
    "                     theme(text = element_text(size = 20))\n",
    "\n",
    "accuracy_plot_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d3464-233f-4400-aab2-a0c66da83f8a",
   "metadata": {},
   "source": [
    "Now we see that the maximum accuracy occurs when $K$ is 5. Thus, we can go ahead using this value of $K$ with the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33541ac1-848d-4d4f-8647-1b8041ffcef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_tune_2 <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 5) |>\n",
    "                set_engine(\"kknn\") |>\n",
    "                set_mode(\"classification\")\n",
    "\n",
    "pulsar_fit <- workflow() |>\n",
    "                add_recipe(pulsar_recipe) |>\n",
    "                add_model(knn_tune_2) |>\n",
    "                fit(data = pulsar_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13883fb9-879b-4381-b9d0-3f7e40b4d1c7",
   "metadata": {},
   "source": [
    "Now, we are ready to predict the class labels for our test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3c4388-e81a-4817-a558-d979c8dccec2",
   "metadata": {},
   "source": [
    "## Making the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56c540-6c14-4f1d-a0b7-068523659813",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_predictions <- predict(pulsar_fit , pulsar_testing) |>\n",
    "       bind_cols(pulsar_testing)\n",
    "\n",
    "\n",
    "print(\"Table 8\")\n",
    "head(pulsar_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d569cf-fbe0-4996-9926-584484a94d69",
   "metadata": {},
   "source": [
    "Now, we calculate the accuracy of our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e9c4f8-5319-4740-861a-4504f934008b",
   "metadata": {},
   "source": [
    "## Calculating the accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6120287-d641-441b-905f-27e92b72dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_accuracy <- pulsar_predictions |>\n",
    "                     metrics(truth = class, estimate = .pred_class) \n",
    "\n",
    "print(\"Table 9\")\n",
    "pulsar_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b4d48f-d975-47fe-af4d-f48bc253f324",
   "metadata": {},
   "source": [
    "Let's have a look at the confusion matrix as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e22c3d-a07c-49bc-9bb1-e199d47a1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_mat <- pulsar_predictions |> \n",
    "                conf_mat(truth = class, estimate = .pred_class)\n",
    "\n",
    "print(\"Table 10\")\n",
    "pulsar_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6065ea6-6555-464c-93c4-a82d0aa12076",
   "metadata": {},
   "source": [
    "## Visualizing our accuracy of our model\n",
    "\n",
    "We can now try and visualize the accuracy of our predictions by plotting some predictors of the testing data and their predictions to see how similar they are to each other. For this instance, let's just see the comparisons between the plots of mean integrated profile versus the standard deviation of the integrated profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86efad2d-5590-492e-85df-2b111a40bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 20, repr.plot.height = 5)\n",
    "\n",
    "plot_mean_ip_std_ip_test <- ggplot(pulsar_testing, aes(x=mean_ip_scaled, y=std_ip_scaled, color=class)) + \n",
    "                                geom_point(alpha=0.6) + \n",
    "                                ggtitle('[Figure 10] Mean IP vs Standard Deviation of IP for Testing Data') +\n",
    "                                labs(x= 'Mean IP', y= 'Standard Deviation of IP') +\n",
    "                                theme(text=element_text(size=20))\n",
    "\n",
    "plot_mean_ip_std_ip_pred <- ggplot(pulsar_predictions, aes(x=mean_ip_scaled, y=std_ip_scaled, color=.pred_class)) + \n",
    "                                geom_point(alpha = 0.5) + \n",
    "                                ggtitle('[Figure 11] Mean IP vs Standard Deviation of IP for Predictions') +\n",
    "                                labs(x= 'Mean IP', y= 'Standard Deviation of IP') +\n",
    "                                theme(text=element_text(size=20))\n",
    "\n",
    "plot_grid(plot_mean_ip_std_ip_test, plot_mean_ip_std_ip_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678d2cb-8484-4f34-af1f-e4477305ad17",
   "metadata": {},
   "source": [
    "Now comparing the plots between Excess Kurtosis and Mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf43736d-9a33-47e2-8255-df7a056dd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 20, repr.plot.height = 5)\n",
    "\n",
    "plot_mean_ip_ek_ip_test <- ggplot(pulsar_testing, aes(x=mean_ip_scaled, y=ek_ip_scaled, color=class)) + \n",
    "                                geom_point(alpha=0.6) + \n",
    "                                ggtitle('[Figure 12] Excess Kurtosis vs Mean of IP for Testing Data') +\n",
    "                                labs(x= 'Mean IP', y= 'Excess Kurtosis of IP') +\n",
    "                                theme(text=element_text(size=20))\n",
    "\n",
    "plot_mean_ip_ek_ip_pred <- ggplot(pulsar_predictions, aes(x=mean_ip_scaled, y=ek_ip_scaled, color=.pred_class)) + \n",
    "                                geom_point(alpha = 0.5) + \n",
    "                                ggtitle('[Figure 13] Excess Kurtosis vs Mean of IP for Predictions') +\n",
    "                                labs(x= 'Mean IP', y= 'Excess Kurtosis of IP') +\n",
    "                                theme(text=element_text(size=20))\n",
    "\n",
    "plot_grid(plot_mean_ip_ek_ip_test, plot_mean_ip_ek_ip_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3348ec-4c46-4dc9-a1e7-3af9d1418c7e",
   "metadata": {},
   "source": [
    "Now comparing the plots between Skewness and Mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c819ed-32d8-4fe6-a878-b1f523f0eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 20, repr.plot.height = 5)\n",
    "\n",
    "plot_mean_ip_sk_ip_test <- ggplot(pulsar_testing, aes(x=mean_ip_scaled, y=sk_ip_scaled, color=class)) + \n",
    "                                geom_point(alpha=0.6) + \n",
    "                                ggtitle('[Figure 14] Skewness vs Mean of IP for Testing Data') +\n",
    "                                labs(x= 'Mean IP', y= 'Skewness of IP') +\n",
    "                                theme(text=element_text(size=20))\n",
    "\n",
    "plot_mean_ip_sk_ip_pred <- ggplot(pulsar_predictions, aes(x=mean_ip_scaled, y=sk_ip_scaled, color=.pred_class)) + \n",
    "                                geom_point(alpha = 0.5) + \n",
    "                                ggtitle('[Figure 15] Skewness vs Mean of IP for Predictions') +\n",
    "                                labs(x= 'Mean IP', y= 'Skewness of IP') +\n",
    "                                theme(text=element_text(size=20))\n",
    "\n",
    "plot_grid(plot_mean_ip_sk_ip_test, plot_mean_ip_sk_ip_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d651ec-192c-4002-a09f-2399848575e3",
   "metadata": {},
   "source": [
    "From the visualizations above, we see that the prediction graphs look very similar to the testing data which shows that we have a pretty accurate model for approximating pulsars from data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d11af",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "For this project, we decided to use $K$-nearest neighbors classification.\n",
    "\n",
    "First, we read the data straight from the web that provided the Pulsar Star data and store it a reference to locally to work upon it.\n",
    "\n",
    "To make the predictor model, we first have to make our data ready for processing. The data given was in two basic sets: Integrated Profile and DM-SNR curve. We selected the Integrated Profile set because both of these sets consist of similar measurements but in different forms, thus training the model on both sets would be redundant. Moreover, when making a ggpairs plot with all the predictors, we saw that the Integrated Profile predictors had very less overlap between the two classes, thus making them ideal for using to train our model. Then we scaled the data around the center for the predictor columns, so that the difference in the scale of all the predictors does not negatively affect the accuracy of the $K$-nn classification model which is based on the Euclidean distance between datapoints. Then we split this data into the training and the testing set by 75% and 25%, respectively.\n",
    "\n",
    "Now working with our training set we check for any missing data which could increase complications down the line, luckily there were none. While analyzing our data, we saw that only 9.2% of the data set was made up of pulsars so we oversampled it so that the ratio of pulsars to non-pulsars was 1:1, so that the model is not more biased towards predicting the non-rare class over the rarer one.\n",
    "\n",
    "After this we used $K$-nearest neighbors classification with cross validation of 5 folds on our data using $K$ from 1 to 100 in steps of 10. After getting the accuracy or each $K$, we observed that the highest accuracy was between 1 and 20, thus we ran it again but with $K$ from 1 to 20 with steps of 1. Again, we plotted the accuracies and found the height accuracy to be at $K = 5$.\n",
    "\n",
    "Now we trained out model with $K$ neighbors set to 5. We used the model against our testing data and obtained an accuracy of approximately 92%. We further visualized our results by comparing the predicted class (pulsar/non-pulsar) against the true class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b81cc-7552-47c8-b2c2-af66667e7ae2",
   "metadata": {},
   "source": [
    "## Discussions\n",
    "\n",
    "The aim of this study is to investigate the predictors that are important for identifying pulsars and predicting their presence based on their Integrated Profile statistics. \n",
    "\n",
    "After analyzing the dataset, it was found that four predictors, Mean, Standard Deviation, Excess Kurtosis, and Skewness of the Integrated Profile provide unique information on their intrinsic relationship with each observation to varying degrees. The model's accuracy was finally found to be 92%, which was higher than expected, indicating that the chosen predictors are crucial in predicting the presence of pulsars based on integrated profile statistics. The unexpectedly high accuracy might also be the result of us up-sampling our class column which mitigated the issue of one class being rare as compared to the other class, and also the fact that we fine tuned the value of $K$ by testing for various different values and finding the final value which gave the best possible results for us.\n",
    "\n",
    "The findings of this study have important implications for future research, as they provide fundamental knowledge for analyzing the most important properties of pulsars and for designing effective classification models. Furthermore, the high accuracy of the model leads to questions for future research, such as the classification of other neutron stars, such as magnetars or lower magnitude stars. Moreover, here we are predicting if an observation is a pulsar or not, but in the future we could try and predict more in-depth details of pulsars, such as their age or origin. In conclusion, the findings of this study provide valuable insights into the importance of integrated profile statistics in the identification of pulsars and highlight the potential for further research to improve our understanding of these fascinating celestial objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863d099-574d-42f5-ae35-b17f2d59991d",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Dataset:\n",
    "- R. J. Lyon, B. W. Stappers, S. Cooper, J. M. Brooke, J. D. Knowles, Fifty Years of Pulsar Candidate Selection: From simple filters to a new principled real-time classification approach, Monthly Notices of the Royal Astronomical Society 459 (1), 1104-1123, DOI: 10.1093/mnras/stw656\n",
    "https://archive.ics.uci.edu/ml/datasets/HTRU2\n",
    "\n",
    "Papers:\n",
    "- R. J. Lyon, 'Why Are Pulsars Hard To Find?', PhD Thesis, University of Manchester, 2016.\n",
    "- D. R. Lorimer and M. Kramer, 'Handbook of Pulsar Astronomy', Cambridge University Press, 2005."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
